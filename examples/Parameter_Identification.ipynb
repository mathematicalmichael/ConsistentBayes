{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to All in One](#All-in-One)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sstats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as wid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(num_observations):\n",
    "    return np.ones(num_observations).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setup \n",
    "\n",
    "- We have a one-dimensional input space $\\Lambda \\subset \\mathcal{R}$ \n",
    "    - we choose some nominal value $\\lambda_0$ to represent a true parameter that we attempt to identify\n",
    "    - we map this value to the output space and perturb it with noise from a mean-zero gaussian distribution with\n",
    "    - we use an initial distribution that is gaussian\n",
    "    - we propagate $N$ samples from this disribution, so the output matrix has each sample in a column. \n",
    "    \n",
    "- Let $M$ denote the number of observations made of an experiment (number of trials/repetitions)\n",
    "    - these are rows in our output matrix.\n",
    "    \n",
    "- We define our map $A: \\mathcal{R} \\to \\mathcal{R}^M$ to repeat the values and represent multiple trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT SPACE PARAMETERS\n",
    "np.random.seed(1)\n",
    "prior_mean = 0.0\n",
    "prior_std = 0.25\n",
    "lam_true = 0.25\n",
    "lambda_true = np.array([[lam_true]])\n",
    "N = 10000 # number of iid MC input samples used to solve inverse problem \n",
    "\n",
    "# OUTPUT SPACE PARAMETERS\n",
    "data_std = 0.00125\n",
    "M = 50 # number of observations\n",
    "A = define_model(M)\n",
    "true_data = A@lambda_true\n",
    "observed_data = true_data + data_std*np.random.randn(M).reshape(-1,1)\n",
    "initial_dist = sstats.distributions.norm(loc=prior_mean, scale=prior_std)\n",
    "# initial_dist = sstats.distributions.uniform(loc=0, scale=0.5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(true_data[0],[1], c='r', s=100, label='truth')\n",
    "plt.scatter(observed_data,np.ones(M), label='data')\n",
    "plt.legend()\n",
    "plt.xlim(0.15, 0.35)\n",
    "\n",
    "# PLOTTING PARAMETERS\n",
    "ns = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_eval = np.linspace(-1, 1, 5000)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(initial_eval, initial_dist.pdf(initial_eval),c='k',lw=5)\n",
    "for i in range(M):\n",
    "    sample = observed_data[i]\n",
    "    temp_dist = sstats.distributions.norm(loc=sample, scale=data_std)\n",
    "    plt.plot(initial_eval, temp_dist.pdf(initial_eval))\n",
    "# plt.xlim(0.15, 0.3)\n",
    "plt.ylim(0,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input and Output Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate input samples and map them to data space\n",
    "input_samples = initial_dist.rvs(N).reshape(1,-1)\n",
    "print('input sample shape:', input_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define map and output space\n",
    "output_samples = A@input_samples\n",
    "print('output sample shape:', output_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_fun(output_samples):\n",
    "    return (1./M)*np.sum( np.power(np.divide(output_samples - observed_data, data_std), 2), axis=0)\n",
    "mse = mse_fun(output_samples)\n",
    "print('MSE computed. shape:', mse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE min:', mse.min(), 'MSE max:', mse.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterize Data Space\n",
    "\n",
    "- you have to choose some way to characterize the push forward of the initial distribution.\n",
    "- use some sort of parametric fit or kernel density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, l, s = sstats.distributions.gamma.fit(mse)\n",
    "print(a, l, s)\n",
    "gamma_fit = sstats.distributions.gamma(a=a,loc=l,scale=s)\n",
    "\n",
    "d, l, s = sstats.distributions.chi2.fit(mse)\n",
    "chi2_fit = sstats.distributions.chi2(df=d,loc=l,scale=s)\n",
    "\n",
    "gkde_fit = sstats.gaussian_kde(mse,0.0125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = np.linspace(0,10,500)\n",
    "gamma_eval = gamma_fit.pdf(x_eval)\n",
    "chi2_eval = chi2_fit.pdf(x_eval)\n",
    "gkde_eval = gkde_fit.evaluate(x_eval)\n",
    "\n",
    "num_bins = 1000\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(mse, num_bins, density=True)\n",
    "# plt.plot(x_eval, gamma_eval, c='b', label='gamma fit')\n",
    "plt.plot(x_eval, chi2_eval, c='r', label='chi2 fit')\n",
    "plt.plot(x_eval, gkde_eval, ':',c='k', label='gkde fit')\n",
    "plt.xlim(0,5)\n",
    "# plt.ylim(0,4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which approximation method you will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf_initial_dist_PDF(x):\n",
    "#     return chi2_fit.pdf(x)\n",
    "#     return gamma_fit.pdf(x)\n",
    "    return gkde_fit.evaluate(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute pushforward of initial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pf_initial = pf_initial_dist_PDF(mse)\n",
    "print('Pushforward of Initial Distribution computed. shape:', eval_pf_initial.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define observed density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dist = sstats.distributions.gamma(a=M/2.0, scale=2.0/M)\n",
    "# obs_dist = sstats.distributions.chi2(df=M)\n",
    "eval_obs = obs_dist.pdf(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "# num_bins = 2000\n",
    "# plt.hist(mse, num_bins, density=True)\n",
    "plt.plot(x_eval, pf_initial_dist_PDF(x_eval), c='r', label='chosen fit density evals')\n",
    "# plt.plot(x_eval, obs_dist.pdf(x_eval), c='k', label = 'observed')\n",
    "plt.legend()\n",
    "plt.xlim(0,5)\n",
    "# plt.ylim(0,0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_initial = initial_dist.pdf(input_samples)\n",
    "ratio = np.divide(eval_obs, eval_pf_initial)\n",
    "updated_dist = eval_initial*ratio\n",
    "\n",
    "print('Ratio computed. Mean:', np.mean(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_updated(x):\n",
    "    y = mse_fun(A@x.reshape(1,-1))\n",
    "    return  initial_dist.pdf(x)*(obs_dist.pdf(y)/pf_initial_dist_PDF(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrogate Updated Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(input_samples, updated_dist)\n",
    "# plt.plot(initial_eval, eval_updated(initial_eval))\n",
    "plt.vlines(0.25,0,200)\n",
    "plt.xlim(0.15, 0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Accept/Reject and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = np.random.rand(N)\n",
    "accepted_inds = [i for i in range(N) if ratio[i] > rn[i]]\n",
    "# plt.scatter(input_samples[0,accepted_inds], updated_dist[0,accepted_inds])\n",
    "g = sstats.gaussian_kde(input_samples[0,accepted_inds], bw_method=1)\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(M-1):\n",
    "    sample = observed_data[i]\n",
    "    temp_dist = sstats.distributions.norm(loc=sample, scale=data_std)\n",
    "    plt.plot(initial_eval, temp_dist.pdf(initial_eval), c='k', alpha=0.05)\n",
    "plt.plot(initial_eval, sstats.distributions.norm.pdf(loc=observed_data[M-1], scale=data_std, x=initial_eval), c='k', alpha=0.25, label='observations')\n",
    "\n",
    "temp_dist = sstats.distributions.norm(loc=0.25, scale=data_std)\n",
    "sample = input_samples[0,accepted_inds[0]]\n",
    "plt.scatter(sample, temp_dist.pdf(sample), c='red', alpha=1, label='accepted samples')\n",
    "for i in range(1,len(accepted_inds)):\n",
    "    sample = input_samples[0,accepted_inds[i]]\n",
    "    plt.scatter(sample, temp_dist.pdf(sample), c='red', alpha=1)\n",
    "\n",
    "plt.plot(initial_eval, g.evaluate(initial_eval), label='gkde of %d accepted'%len(accepted_inds), c='b')\n",
    "\n",
    "    \n",
    "temp_dist = sstats.distributions.norm(loc=lam_true, scale=data_std)\n",
    "plt.plot(initial_eval, temp_dist.pdf(initial_eval), label='N(%2.2f, %2.5f)'%(lam_true, data_std), c='k')\n",
    "# plt.plot(initial_eval, g.evaluate(initial_eval), label='gkde of %d accepted'%len(accepted_inds), c='b')\n",
    "\n",
    "plt.xlim(0.225,0.275)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makemodel(t):\n",
    "    def model(lam = np.array([[0.25]]) ):\n",
    "        QoI = lam[0,:].reshape(-1,1)*np.exp(-0.5*t)\n",
    "        return QoI.T\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_problem(N = 1000, \n",
    "                prior_mean = 0.0,\n",
    "                prior_std = 0.25,\n",
    "                M = 10, \n",
    "                data_std = 0.0125,\n",
    "                lam_true = 0.25, \n",
    "                start_time = 1, \n",
    "                end_time = 5,\n",
    "                seed=None,\n",
    "                plot=True):\n",
    "    \n",
    "    N, M, seed = int(N), int(M), int(seed) # enforce types \n",
    "    # INPUT SPACE PARAMETERS\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "#     prior_mean = 0.0\n",
    "#     prior_std = 0.25\n",
    "#     lam_true = 0.25\n",
    "    lambda_true = np.array([[lam_true]])\n",
    "#     N = 1000 # number of iid MC input samples used to solve inverse problem \n",
    "\n",
    "    # OUTPUT SPACE PARAMETERS\n",
    "#     data_std = 0.0125\n",
    "#     M = 50 # number of observations\n",
    "#     A = define_model(M)\n",
    "    ####\n",
    "\n",
    "    t = np.linspace(start_time, end_time, M)\n",
    "    ed_model = makemodel(t)\n",
    "    \n",
    "    def model(input_samples):\n",
    "#         output_samples = A@input_samples\n",
    "        output_samples = ed_model(input_samples)\n",
    "        return output_samples\n",
    "    \n",
    "    true_data = model(lambda_true)\n",
    "    \n",
    "    observed_data = true_data + data_std*np.random.randn(M).reshape(-1,1)\n",
    "    obs_data_mean, obs_data_std = np.mean(observed_data), np.std(observed_data)\n",
    "#     print('Stats on observed data:', 'mean:', obs_data_mean, 'sd:', obs_data_std)\n",
    "    initial_dist = sstats.distributions.norm(loc=prior_mean, scale=prior_std)\n",
    "    # initial_dist = sstats.distributions.uniform(loc=0, scale=0.5)\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(10,5))\n",
    "    # plt.scatter(true_data[0],[1], c='r', s=100, label='truth')\n",
    "    # plt.scatter(observed_data,np.ones(M), label='data')\n",
    "    # plt.legend()\n",
    "    # plt.xlim(0.15, 0.35)\n",
    "\n",
    "    # PLOTTING PARAMETERS\n",
    "    num_bins = 100\n",
    "    mesh_sz = 2500\n",
    "    \n",
    "    initial_eval = np.linspace(-1, 1, mesh_sz)\n",
    "    updated_eval = np.linspace(0.2, 0.3, mesh_sz)\n",
    "    \n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20,15))\n",
    "        ### VISUALIZE INITIAL VS DATA OBSERVED\n",
    "\n",
    "        axs[0,0].plot(initial_eval, initial_dist.pdf(initial_eval),c='k',lw=5)\n",
    "        for i in range(M):\n",
    "            sample = observed_data[i]\n",
    "            temp_dist = sstats.distributions.norm(loc=sample, scale=data_std)\n",
    "            axs[0,0].plot(initial_eval, temp_dist.pdf(initial_eval))\n",
    "        # plt.xlim(0.15, 0.3)\n",
    "        axs[0,0].set_ylim(0,2)\n",
    "        axs[0,0].set_title(\"Initial Density and observed data with uncertainty\")\n",
    "\n",
    "\n",
    "    # generate input samples and map them to data space\n",
    "    input_samples = initial_dist.rvs(N).reshape(1,-1)\n",
    "    print('input sample shape:', input_samples.shape)\n",
    "\n",
    "    # define map and output space\n",
    "    output_samples = model(input_samples)\n",
    "    print('output sample shape:', output_samples.shape)\n",
    "\n",
    "    def loss_fun(output_samples):\n",
    "#         return (1./M)*np.sum( np.power(np.divide(output_samples - observed_data, data_std), 2), axis=0)\n",
    "#         return (1./np.sqrt(2*M))*np.sum( np.power(np.divide(output_samples - observed_data, data_std) , 2) - 1.0, axis=0)\n",
    "        return (1./data_std)*(1./np.sqrt(M))*np.sum( output_samples - observed_data, axis=0)\n",
    "    \n",
    "    mse = loss_fun(output_samples)\n",
    "#     print('Loss fun computed. shape:', mse.shape)\n",
    "    print('Loss fun min:', mse.min(), 'MSE max:', mse.max())\n",
    "\n",
    "#     x_eval = np.linspace(-1000,1000,mesh_sz*5)\n",
    "    x_eval = np.linspace(mse.min(), mse.max(), mesh_sz*5)\n",
    "    \n",
    "    ### Define Observed and Pushforward of Initial\n",
    "    # FIT PF\n",
    "#     a, l, s = sstats.distributions.gamma.fit(mse)\n",
    "#     # print(a, l, s)\n",
    "#     gamma_fit = sstats.distributions.gamma(a=a,loc=l,scale=s)\n",
    "\n",
    "#     d, l, s = sstats.distributions.chi2.fit(mse)\n",
    "#     chi2_fit = sstats.distributions.chi2(df=d,loc=l,scale=s)\n",
    "\n",
    "    gkde_fit = sstats.gaussian_kde(mse)\n",
    "\n",
    "\n",
    "    def pf_initial_dist_PDF(x):\n",
    "    #     return chi2_fit.pdf(x)\n",
    "#         return gamma_fit.pdf(x)\n",
    "        return gkde_fit.evaluate(x)\n",
    "\n",
    "    eval_pf_initial = pf_initial_dist_PDF(mse)\n",
    "    # print('Pushforward of Initial Distribution computed. shape:', eval_pf_initial.shape)\n",
    "\n",
    "    obs_dist = sstats.distributions.norm()\n",
    "#     obs_dist = sstats.distributions.gamma(a=M/2.0, scale=2.0/M)\n",
    "    # obs_dist = sstats.distributions.chi2(df=M)\n",
    "    eval_obs = obs_dist.pdf(mse)\n",
    "\n",
    "\n",
    "#     gamma_eval = gamma_fit.pdf(x_eval)\n",
    "#     chi2_eval = chi2_fit.pdf(x_eval)\n",
    "    gkde_eval = gkde_fit.evaluate(x_eval)\n",
    "    if plot:\n",
    "        axs[0,1].hist(mse, num_bins, density=True)\n",
    "    #     axs[0,1].plot(x_eval, gamma_eval, c='b', label='gamma fit')\n",
    "    #     axs[0,1].plot(x_eval, chi2_eval, c='r', label='chi2 fit')\n",
    "        axs[0,1].plot(x_eval, gkde_eval, '--',c='r', label='gkde fit')\n",
    "        axs[0,1].plot(x_eval, obs_dist.pdf(x_eval), c='k', label = 'observed')\n",
    "        axs[0,1].set_xlim(-5,5)\n",
    "        axs[0,1].set_ylim(0,np.max(gkde_eval))\n",
    "        axs[0,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "    ### SOLVE INVERSE PROBLEM \n",
    "    eval_initial = initial_dist.pdf(input_samples)\n",
    "#     print('MIN oF PF_INPUT_EVAL:.', np.min(eval_pf_initial))\n",
    "\n",
    "    ratio = np.divide(eval_obs, eval_pf_initial) # COMPUTE RATIO\n",
    "    updated_dist = eval_initial*ratio # EVALUATE UPDATED DENSITY ON INPUT SAMPLES\n",
    "\n",
    "#     print('Ratio computed. Mean:', np.mean(ratio))\n",
    "\n",
    "    ### VISUALIZE RESULTS\n",
    "    def eval_updated(x):\n",
    "        y = loss_fun(model(x.reshape(1,-1)))\n",
    "        return  initial_dist.pdf(x)*np.divide(obs_dist.pdf(y), pf_initial_dist_PDF(y))\n",
    "    \n",
    "    input_samples = input_samples.ravel() # reshape 1D vectors for easier access\n",
    "    updated_dist = updated_dist.ravel()\n",
    "    \n",
    "    \n",
    "    \n",
    "    updated_evaluated_on_mesh = eval_updated(updated_eval) # VISUALIZE UPDATED DENSITY\n",
    "    updated_eval_at_truth = eval_updated(np.array([lam_true]))\n",
    "    \n",
    "    max_input_sample_index = np.where(updated_dist == np.max(updated_dist))[0][0]\n",
    "    rel_error_mc = np.abs( (input_samples[max_input_sample_index] - lam_true )/lam_true )\n",
    "    \n",
    "    max_eval_sample_index = np.where(updated_evaluated_on_mesh == np.max(updated_evaluated_on_mesh))[0][0]\n",
    "    rel_error_mesh = np.abs( (updated_eval[max_eval_sample_index] - lam_true )/lam_true )\n",
    "    \n",
    "    if plot:\n",
    "        axs[1,1].vlines(lam_true, 0, np.max(updated_evaluated_on_mesh), color='b', label='true value')\n",
    "        axs[1,1].plot(updated_eval, updated_evaluated_on_mesh, c='k', label='updated eval, mesh: %d'%mesh_sz)\n",
    "        axs[1,1].scatter(input_samples[max_input_sample_index], updated_dist[max_input_sample_index], c='b', s=250, label='Max (MC), RE:%1.2e'%rel_error_mc)\n",
    "    #     axs[1,1].scatter(0.25, updated_eval_at_truth, s=25, label='density val @ truth: %2.4f'%updated_eval_at_truth)\n",
    "        axs[1,1].scatter(updated_eval[max_eval_sample_index], updated_evaluated_on_mesh[max_eval_sample_index], c='orange', s=200, label='Max (mesh), RE:%1.2e'%rel_error_mesh)\n",
    "\n",
    "    #     axs[1,1].set_xlim(0.15, 0.35)\n",
    "        axs[1,1].set_xlim(0.2,0.3)\n",
    "        # axs[1,1].set_ylim(0, 200)\n",
    "        axs[1,1].set_title('Updated Density evaluated')\n",
    "    \n",
    "\n",
    "    # PLOT RESULTS AND OBSERVED DATA\n",
    "    # np.random.seed(23)\n",
    "    rn = np.random.rand(N)\n",
    "    accepted_inds = [i for i in range(N) if ratio[i] > rn[i]]\n",
    "    if plot:\n",
    "        # axs[1,0].scatter(input_samples[0,accepted_inds], updated_dist[0,accepted_inds])\n",
    "        if len(accepted_inds) > 1:\n",
    "            g = sstats.gaussian_kde(input_samples[accepted_inds])\n",
    "            axs[1,0].plot(initial_eval, g.evaluate(initial_eval), label='gkde of %d accepted'%len(accepted_inds), c='b', lw=2)\n",
    "\n",
    "        for i in range(M-1):\n",
    "            sample = observed_data[i]\n",
    "            temp_dist = sstats.distributions.norm(loc=sample, scale=data_std)\n",
    "            axs[1,0].plot(initial_eval, temp_dist.pdf(initial_eval), c='k', alpha=0.1)\n",
    "        axs[1,0].plot(initial_eval, sstats.distributions.norm.pdf(loc=observed_data[M-1], scale=data_std, x=initial_eval), c='orange', alpha=0.75, label='observations') # OBSERVED DATA\n",
    "\n",
    "\n",
    "        if len(accepted_inds) > 1:\n",
    "            sample = input_samples[accepted_inds[0]]\n",
    "            axs[1,0].scatter(sample, g.evaluate(sample), c='red', alpha=1, label='accepted samples')\n",
    "            for i in range(1,len(accepted_inds)):\n",
    "                sample = input_samples[accepted_inds[i]]\n",
    "                axs[1,0].scatter(sample, g.evaluate(sample), c='red', alpha=1)\n",
    "            axs[1,1].scatter(input_samples[accepted_inds], updated_dist[accepted_inds], c='red', s=50, label='accepted')\n",
    "        axs[1,1].scatter(input_samples, updated_dist,  c='k', s=10, label='initial samples')    \n",
    "\n",
    "\n",
    "        reference_dist = sstats.distributions.norm(loc=lam_true, scale=data_std)\n",
    "        ref_dist_eval = reference_dist.pdf(initial_eval)\n",
    "#         axs[1,0].plot(initial_eval, ref_dist_eval, label='N(%2.4f, %2.5f$^2$)'%(lam_true, data_std), c='green', lw=3, alpha=1.0)\n",
    "        axs[1,0].vlines(lam_true, 0, np.max(ref_dist_eval))\n",
    "        \n",
    "        if M == -1: # can't compute std on sample size of 1, this makes no sense for timeseries\n",
    "            approx_dist = sstats.distributions.norm(loc=obs_data_mean, scale=obs_data_std)\n",
    "            axs[1,0].plot(initial_eval, approx_dist.pdf(initial_eval), label='N(%2.4f, %2.5f$^2$)'%(obs_data_mean, obs_data_std), c='purple', lw=3, alpha=1.0)\n",
    "            # axs[1,0].plot(initial_eval, g.evaluate(initial_eval), label='gkde of %d accepted'%len(accepted_inds), c='b')\n",
    "\n",
    "        axs[1,0].set_xlim(0.2,0.3)\n",
    "    #     axs[1,0].set_xlim(0.15, 0.35)\n",
    "        axs[1,0].set_title(\"Updated Density, observed data with uncertainty\")\n",
    "        axs[1,0].legend(fontsize=12)\n",
    "        axs[1,1].legend(fontsize=12)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "        \n",
    "    SUMMARY = {\n",
    "        'N': N,\n",
    "        'M': M, \n",
    "        'seed': seed, \n",
    "        'prior_mean': prior_mean,\n",
    "        'prior_std': prior_std,\n",
    "        'data_std': data_std,\n",
    "        'lam_true': lam_true,\n",
    "        'mud_val': input_samples[max_input_sample_index],\n",
    "        'rel_error_mc': rel_error_mc,\n",
    "        'obs_data_mean': obs_data_mean,\n",
    "        'obs_data_std': obs_data_std,\n",
    "        'num_accepted': len(accepted_inds),\n",
    "        'time': [start_time, end_time],\n",
    "        'mean_r': ratio.mean(),\n",
    "        'mse_min': mse.min(),\n",
    "        'mse_max': mse.max()\n",
    "    }\n",
    "    if not plot:\n",
    "        return SUMMARY, input_samples[accepted_inds], observed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8fbbdee64c43b2a133e4783605a1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1000, continuous_update=False, description='N', max=10000, min=1000, ste…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.solve_problem>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wid.interact_manual(solve_problem, \n",
    "                prior_mean=wid.FloatSlider(min=-0.25, max=0.25, step=0.05, continuous_update=False),  \n",
    "                prior_std=wid.FloatSlider(value=0.25, min=0.125, max=0.5, step=0.125, readout_format='.2e', continuous_update=False),     \n",
    "                data_std=wid.FloatSlider(value=0.01, min=0.0025, max=0.0125, step=0.0025, readout_format='.2e', continuous_update=False),\n",
    "                N = wid.IntSlider(value=500, min=1000, max=10000, step=1000, continuous_update=False), \n",
    "                M = wid.IntSlider(value=1, min=1, max=250, continuous_update=False), \n",
    "                start_time = wid.FloatSlider(value=1, min=1, max=5, step=0.05, continuous_update=False),\n",
    "                end_time = wid.FloatSlider(value=5, min=1, max=5, step=0.05, continuous_update=False),\n",
    "                lam_true = wid.fixed(value=0.25, continuous_update=False),\n",
    "                seed=wid.IntSlider(value=12, min=1, max=21, continuous_update=False),\n",
    "                plot = wid.fixed(True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64262a9090574f83a8902428e119f869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, continuous_update=False, description='N', max=10000, min=500, step=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.make_predictions>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(N = 1000, \n",
    "                prior_mean = 0.0,\n",
    "                prior_std = 0.25,\n",
    "                M = 10, \n",
    "                data_std = 0.001,\n",
    "                lam_true = 0.25, \n",
    "                start_time = 1, \n",
    "                end_time = 5,\n",
    "                seed=None, \n",
    "                plot=False):\n",
    "    S, I, O = solve_problem(N, prior_mean, prior_std, M, data_std, lam_true, start_time, end_time, seed, plot)\n",
    "\n",
    "    start_time, end_time = S['time']\n",
    "    t = np.linspace(start_time, end_time, S['M'])\n",
    "    tt = np.linspace(0, end_time, 1000)\n",
    "    model = makemodel(tt)\n",
    "    u_acc = model(I.reshape(1,-1))\n",
    "    obs_data = O\n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    dd = np.mean(u_acc, axis=1)\n",
    "    plt.plot(tt, dd, c='k', alpha=1, lw=5, label='Mean Predicted Signal')\n",
    "\n",
    "    for i in range(len(I)):\n",
    "        d = u_acc[:,i]\n",
    "        if i==1:\n",
    "            plt.plot(tt, d, c='b', alpha=0.25, lw=1, label='Accepted Samples')\n",
    "        else:\n",
    "            plt.plot(tt, d, c='b', alpha=0.05, lw=1)\n",
    "\n",
    "    plt.scatter(t, obs_data, marker='o', c='r', s=50, alpha=1, label='Observed Data')\n",
    "    plt.plot(tt, model(np.array(S['mud_val']).reshape(-1,1)), c='green', lw=3, label='MUD prediction')\n",
    "    plt.plot(tt, model(), ls=':', c='k', lw=3, label='true signal')\n",
    "\n",
    "    plt.ylabel('Height', fontsize=18)\n",
    "    plt.xlabel('Time (s)', fontsize=18)\n",
    "    plt.title('Recovered Signal based on Accepted Samples', fontsize=28)\n",
    "    plt.legend(fontsize=18, loc='upper left')\n",
    "    plt.xlim([0,5+.05])\n",
    "    plt.ylim([0,0.3])\n",
    "    # plt.hlines(np.mean(I),0,5)\n",
    "    # plt.savefig('recovered{}.png'.format(problem.upper()))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return None\n",
    "\n",
    "wid.interact(make_predictions, \n",
    "                prior_mean=wid.FloatSlider(min=-0.25, max=0.25, step=0.05, continuous_update=False),  \n",
    "                prior_std=wid.FloatSlider(value=0.25, min=0.125, max=0.5, step=0.125, readout_format='.2e', continuous_update=False),     \n",
    "                data_std=wid.FloatSlider(value=0.01, min=0.0025, max=0.0125, step=0.0025, readout_format='.2e', continuous_update=False),\n",
    "                N = wid.IntSlider(value=500, min=500, max=10000, step=1000, continuous_update=False), \n",
    "                M = wid.IntSlider(value=1, min=1, max=50, continuous_update=False), \n",
    "                start_time = wid.FloatSlider(value=1, min=0.25, max=5, step=0.25, continuous_update=False),\n",
    "                end_time = wid.FloatSlider(value=5, min=2, max=10, step=0.25, continuous_update=False),\n",
    "                lam_true = wid.fixed(value=0.25, continuous_update=False),\n",
    "                seed=wid.IntSlider(value=12, min=1, max=21, continuous_update=False),\n",
    "                plot = wid.fixed(False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_true = 0.25\n",
    "prior_mean = 0\n",
    "prior_std = 0.25\n",
    "\n",
    "N = [50*2**n for n in range(8)]\n",
    "M = [2,3,4,5,6,7,8,9, *np.arange(1,11)*10 ] \n",
    "seed = np.random.randint(2,10000,10) \n",
    "assert len(np.unique(seed)) == len(seed) # ensure no repetitions\n",
    "data_std = np.round([0.001*2**n for n in np.linspace(0,np.log2(100),5)],12).ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.meshgrid(N, M, seed, data_std)\n",
    "S = np.concatenate([G[i].ravel().reshape(-1,1) for i in range(4)],axis=1)\n",
    "num_runs = np.int(np.product(np.shape(G))/4.0)\n",
    "np.shape(G), num_runs, S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data_vec():\n",
    "    DATA = {'M': [],\n",
    "     'N': [],\n",
    "     'data_std': [],\n",
    "     'lam_true': [],\n",
    "     'mean_r': [],\n",
    "     'mse_max': [],\n",
    "     'mse_min': [],\n",
    "     'num_accepted': [],\n",
    "     'obs_data_mean': [],\n",
    "     'obs_data_std': [],\n",
    "     'prior_mean': [],\n",
    "     'prior_std': [],\n",
    "     'rel_error_mc': [],\n",
    "     'seed': []}\n",
    "    return DATA\n",
    "\n",
    "def append_summary(SUMMARY, DATA):\n",
    "    for k in SUMMARY.keys():\n",
    "        DATA[k].append(SUMMARY[k])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = init_data_vec()\n",
    "# for i in progressbar.progressbar(range(num_runs)):\n",
    "#     N_, M_, seed_, data_std_ = S[i,:]\n",
    "#     SMRY = solve_problem(N=N_, M=M_, seed=seed_, data_std=data_std_, lam_true=lam_true, prior_mean=prior_mean, prior_std=prior_std, plot=False)\n",
    "#     append_summary(SMRY, DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('saved_run_tuesday.npy', DATA)\n",
    "DATA = np.load('saved_run_tuesday.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.zeros(S.shape)\n",
    "T[:,0] = DATA['N']\n",
    "T[:,1] = DATA['M']\n",
    "T[:,2] = DATA['seed']\n",
    "T[:,3] = DATA['data_std']\n",
    "TT = T.reshape(np.shape(G))\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G[0].shape, G[1].shape, G[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEED EFFECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through M\n",
    "# i = 7 # fix a value of N choice = 7 => N = 6400\n",
    "s = 8 # fix a seed\n",
    "d = 2 # fix assumed error choice = 2 => std = 0.01\n",
    "\n",
    "N_val = 3200\n",
    "i = np.where(np.isin(N,N_val))[0][0]\n",
    "print('N is ', N[i], 'and the data std is', data_std[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for s in range(len(seed)):\n",
    "    A = T[d::5,:][s::10,:][i::8,:]\n",
    "    plt.plot(A[:,1], np.array(DATA['obs_data_mean'])[d::5][s::10][i::8], c='k', alpha=0.25)\n",
    "plt.hlines(lam_true, 0,100)\n",
    "plt.title('Approximated MEAN')\n",
    "plt.xlabel('number of experiments')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for s in range(len(seed)):\n",
    "    A = T[d::5,:][s::10,:][i::8,:]\n",
    "    ds = A[-1,-1]\n",
    "    plt.plot(A[:,1], np.array(DATA['obs_data_std'])[d::5][s::10][i::8], c='k', alpha=0.25)\n",
    "plt.hlines(ds, 0,100)\n",
    "plt.title('Approximated STDEV')\n",
    "plt.xlabel('number of experiments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for s in range(len(seed)):\n",
    "    A = T[d::5,:][s::10,:][i::8,:]\n",
    "    nn = A[0,0]\n",
    "    plt.semilogy(A[:,1], 100*np.array(DATA['rel_error_mc'])[d::5][s::10][i::8], c='k', alpha=0.25)\n",
    "plt.title('Relative Error, N=%d'%nn)\n",
    "# plt.ylim([1E-5, 1E-2])\n",
    "plt.xlabel('number of experiments')\n",
    "plt.ylabel('Percentage Relative Error')\n",
    "plt.hlines(1,0,100, label='1%')\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for s in range(len(seed)):\n",
    "    A = T[d::5,:][s::10,:][i::8,:]\n",
    "    if s<9:\n",
    "        plt.plot(A[:,1], np.abs(np.array(DATA['mse_min'])[d::5][s::10][i::8]), c='b', alpha=0.25)\n",
    "        plt.plot(A[:,1], np.array(DATA['mse_max'])[d::5][s::10][i::8], c='r', alpha=0.25)\n",
    "    else:\n",
    "        plt.plot(A[:,1], np.abs(np.array(DATA['mse_min'])[d::5][s::10][i::8]), c='b', alpha=0.25, label='min')\n",
    "        plt.plot(A[:,1], np.array(DATA['mse_max'])[d::5][s::10][i::8], c='r', alpha=0.25, label='max')   \n",
    "plt.title('Range QoI')\n",
    "plt.legend()\n",
    "plt.xlabel('number of experiments')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for s in range(len(seed)):\n",
    "    A = T[d::5,:][s::10,:][i::8,:]\n",
    "    if s<9:\n",
    "        plt.loglog(A[:,1], np.abs(np.array(DATA['mse_min']) - np.array(DATA['mse_max']))[d::5][s::10][i::8], c='r', alpha=0.25)\n",
    "    else:\n",
    "        plt.loglog(A[:,1], np.abs(np.array(DATA['mse_min']) - np.array(DATA['mse_max']))[d::5][s::10][i::8], c='r', alpha=0.25, label='diff')   \n",
    "plt.loglog(A[:,1], np.sqrt(10000*np.array(A[:,1])))\n",
    "plt.title('Difference QoI')\n",
    "plt.legend()\n",
    "plt.xlabel('number of experiments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for s in range(len(seed)):\n",
    "    A = T[d::5,:][s::10,:][i::8,:]\n",
    "    if s<9:\n",
    "        plt.plot(A[:,1], np.array(DATA['mean_r'])[d::5][s::10][i::8] , c='r', alpha=0.25)\n",
    "    else:\n",
    "        plt.plot(A[:,1], np.array(DATA['mean_r'])[d::5][s::10][i::8] , c='r', alpha=0.25, label='mean ratio')   \n",
    "plt.title('Mean of ratio')\n",
    "plt.legend()\n",
    "plt.xlabel('number of experiments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependence on N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through N\n",
    "plt.figure(figsize=(20,10))\n",
    "s = 1 # fix a seed < 10\n",
    "d = 0 # fix assumed error choice = 2 => std = 0.01\n",
    "M_vals = [10, 100]\n",
    "M_inds = np.where(np.isin(M,M_vals))[0]\n",
    "colors = ['blue', 'orange', 'black', 'red', 'black', 'magenta']\n",
    "for k in range(len(M_inds)): # 12 => M=50\n",
    "    for s in range(len(seed)):\n",
    "        j=M_inds[k]*8\n",
    "        A = T[d::5,:][s::10,:][j:(8+j),:]\n",
    "        mm = T[d::5,:][s::10,:][j:(8+j),:][0,1] # M value\n",
    "        if s < 1:\n",
    "            plt.semilogy(A[:,0], 100*np.abs(np.array(DATA['mse_min']))[d::5][s::10][j:(8+j)], c=colors[k], alpha=1, label = 'Min M = %d'%mm)\n",
    "            plt.semilogy(A[:,0], 100*np.array(DATA['mse_max'])[d::5][s::10][j:(8+j)], c=colors[k+2], alpha=1, label = 'Max M = %d'%mm)\n",
    "\n",
    "        else:\n",
    "            plt.semilogy(A[:,0], 100*np.abs(np.array(DATA['mse_min']))[d::5][s::10][j:(8+j)], c=colors[k], alpha=1)\n",
    "            plt.semilogy(A[:,0], 100*np.array(DATA['mse_max'])[d::5][s::10][j:(8+j)], c=colors[k+2], alpha=1)\n",
    "plt.title('Relative Error')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Percentage relative error')\n",
    "# plt.hlines(1,0,6400, label='1%',lw=2)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through N\n",
    "plt.figure(figsize=(20,10))\n",
    "s = 1 # fix a seed < 10\n",
    "d = 4 # fix assumed error choice = 2 => std = 0.01\n",
    "M_vals = [10, 100]\n",
    "M_inds = np.where(np.isin(M,M_vals))[0]\n",
    "colors = ['blue', 'orange', 'black', 'red']\n",
    "for k in range(len(M_inds)): # 12 => M=50\n",
    "    for s in range(10):\n",
    "        j=M_inds[k]*8\n",
    "        A = T[d::5,:][s::10,:][j:(8+j),:]\n",
    "        mm = T[d::5,:][s::10,:][j:(8+j),:][0,1] # M value\n",
    "        if s < 1:\n",
    "            plt.semilogy(A[:,0], 100*np.array(DATA['rel_error_mc'])[d::5][s::10][j:(8+j)], c=colors[k], alpha=1, label = 'M = %d'%mm)\n",
    "        else:\n",
    "            plt.semilogy(A[:,0], 100*np.array(DATA['rel_error_mc'])[d::5][s::10][j:(8+j)], c=colors[k], alpha=1)\n",
    "plt.title('Relative Error')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Percentage relative error')\n",
    "plt.hlines(1,0,6400, label='1%',lw=2)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More precise data = less stable mean ratio value\n",
    "`data_std = 0.001` yields stable means for `N>3200`\n",
    "`data_std = 0.0316` is good for `N>1000`\n",
    "`data_st = 0.01` is good for `N>1000`\n",
    "\n",
    "I think choosing `data_std = 0.01` and `N = 5000` should provide a good mix of speed/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through N\n",
    "plt.figure(figsize=(20,10))\n",
    "s = 1 # fix a seed < 10\n",
    "d = 2 # fix assumed error choice = 2 => std = 0.01\n",
    "# M_vals = [10, 100]\n",
    "M_vals =  [2,3,4,5,6,7,8,9, *np.arange(1,11)*10 ]\n",
    "M_inds = np.where(np.isin(M,M_vals))[0]\n",
    "# colors = ['blue', 'orange', 'black', 'red']\n",
    "colors = np.linspace(0,0.75, len(M_vals))\n",
    "for k in range(len(M_vals)): # 12 => M=50\n",
    "    for s in range(len(seed)):\n",
    "        j=M_inds[k]*8\n",
    "        A = T[d::5,:][s::10,:][j:(8+j),:]\n",
    "        mm = T[d::5,:][s::10,:][j:(8+j),:][0,1] # M value\n",
    "        if s < 1:\n",
    "            plt.semilogy(A[:,0], np.array(DATA['mean_r'])[d::5][s::10][j:(8+j)], c=colors[k]*np.ones(3), alpha=0.8, label = 'M = %d'%mm)\n",
    "        else:\n",
    "            plt.semilogy(A[:,0], np.array(DATA['mean_r'])[d::5][s::10][j:(8+j)], c=colors[k]*np.ones(3), alpha=0.8)\n",
    "plt.title('Mean of Ratio')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Mean of Ratio')\n",
    "plt.ylim([1E-4, 2])\n",
    "plt.xlim([0,6400])\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "print('data_std = ', data_std[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary M (new runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ = 3000\n",
    "data_std_ = 0.01\n",
    "# M_list = [2,3,4,5,6,7,8,9, *np.arange(1,21)*5 ]\n",
    "M_list = [5, 10, 25, 50, 100, 200]\n",
    "num_seeds = 10\n",
    "lam_true = 0.25\n",
    "prior_mean = 0\n",
    "prior_std = 0.25\n",
    "\n",
    "seed_list = np.random.randint(2,10000,num_seeds) \n",
    "assert len(np.unique(seed)) == len(seed) # ensure no repetitions\n",
    "\n",
    "# ax = plt.subplot(1,1,1)\n",
    "DDD = {}\n",
    "for seed_ in progressbar.progressbar(seed_list):\n",
    "    DD = init_data_vec()\n",
    "    for M_ in M_list:\n",
    "        SMRY = solve_problem(N=N_, M=M_, seed=seed_, data_std=data_std_, lam_true=lam_true, prior_mean=prior_mean, prior_std=prior_std, plot=False)\n",
    "        append_summary(SMRY, DD)\n",
    "#     print(, DD['rel_error_mc'])\n",
    "    DDD[str(seed_)] = DD\n",
    "print('Done running.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for seed_ in seed_list:\n",
    "    plt.semilogy(DDD[str(seed_)]['M'], DDD[str(seed_)]['mean_r'], color='k', alpha=0.5)\n",
    "plt.ylim([1E-1, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary N (new runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
